{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание 7: Кластеризация\n",
    "\n",
    "Анализ методов неконтролируемого обучения на различных датасетах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт необходимых библиотек\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Для визуализации\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Для предобработки\n",
    "from sklearn.preprocessing import StandardScaler, SimpleImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Для кластеризации\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "\n",
    "# Для оценки качества\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "# Параметры визуализации\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "# Создание папок для артефактов\n",
    "os.makedirs('artifacts/figures', exist_ok=True)\n",
    "os.makedirs('artifacts/labels', exist_ok=True)\n",
    "\n",
    "print('Все необходимые библиотеки импортированы')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Датасет 1: Анализ и кластеризация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка и EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка датасета 1\n",
    "df1 = pd.read_csv('data/S07-hw-dataset-01.csv')\n",
    "\n",
    "print('=== Датасет 1: Информация ===' )\n",
    "print(f'Размер: {df1.shape}')\n",
    "print(f'\\nПервые строки:')\n",
    "print(df1.head())\n",
    "print(f'\\nТип данных:')\n",
    "print(df1.info())\n",
    "print(f'\\nСтатистика:')\n",
    "print(df1.describe())\n",
    "print(f'\\nПропущенные значения:')\n",
    "print(df1.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка датасета 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отделяем sample_id от признаков\n",
    "sample_ids_1 = df1['sample_id'].copy()\n",
    "X1_raw = df1.drop('sample_id', axis=1)\n",
    "\n",
    "# Обработка пропущенных значений\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X1_imputed = imputer.fit_transform(X1_raw)\n",
    "\n",
    "# Стандартизация признаков\n",
    "scaler = StandardScaler()\n",
    "X1 = scaler.fit_transform(X1_imputed)\n",
    "\n",
    "print('Датасет 1 предобработан')\n",
    "print(f'Форма после предобработки: {X1.shape}')\n",
    "print(f'Среднее: {X1.mean(axis=0)}')\n",
    "print(f'Стандартное отклонение: {X1.std(axis=0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans кластеризация для датасета 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестирование KMeans с разными k\n",
    "k_range = range(2, 21)\n",
    "silhouette_scores_1_km = []\n",
    "davies_bouldin_scores_1_km = []\n",
    "calinski_harabasz_scores_1_km = []\n",
    "kmeans_models_1 = {}\n",
    "\n",
    "for k in k_range:\n",
    "    # KMeans кластеризация\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels_km = kmeans.fit_predict(X1)\n",
    "    kmeans_models_1[k] = (kmeans, labels_km)\n",
    "    \n",
    "    # Расчет метрик\n",
    "    sil_score = silhouette_score(X1, labels_km)\n",
    "    db_score = davies_bouldin_score(X1, labels_km)\n",
    "    ch_score = calinski_harabasz_score(X1, labels_km)\n",
    "    \n",
    "    silhouette_scores_1_km.append(sil_score)\n",
    "    davies_bouldin_scores_1_km.append(db_score)\n",
    "    calinski_harabasz_scores_1_km.append(ch_score)\n",
    "    \n",
    "    print(f'k={k}: Silhouette={sil_score:.4f}, Davies-Bouldin={db_score:.4f}, Calinski-Harabasz={ch_score:.4f}')\n",
    "\n",
    "# Выбор лучшего k по silhouette\n",
    "best_k_1_km = list(k_range)[np.argmax(silhouette_scores_1_km)]\n",
    "print(f'\\nЛучшее k для KMeans: {best_k_1_km}')\n",
    "print(f'Лучший silhouette score: {max(silhouette_scores_1_km):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN кластеризация для датасета 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестирование DBSCAN с разными eps\n",
    "eps_range = np.linspace(0.3, 2.0, 15)\n",
    "min_samples = 5\n",
    "\n",
    "silhouette_scores_1_db = []\n",
    "davies_bouldin_scores_1_db = []\n",
    "calinski_harabasz_scores_1_db = []\n",
    "noise_percentages_1_db = []\n",
    "dbscan_models_1 = {}\n",
    "\n",
    "for eps in eps_range:\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "    labels_db = dbscan.fit_predict(X1)\n",
    "    dbscan_models_1[eps] = (dbscan, labels_db)\n",
    "    \n",
    "    n_clusters = len(set(labels_db)) - (1 if -1 in labels_db else 0)\n",
    "    noise_points = np.sum(labels_db == -1)\n",
    "    noise_percent = (noise_points / len(labels_db)) * 100\n",
    "    noise_percentages_1_db.append(noise_percent)\n",
    "    \n",
    "    if n_clusters > 1 and len(set(labels_db)) > 1:\n",
    "        sil_score = silhouette_score(X1, labels_db)\n",
    "        db_score = davies_bouldin_score(X1, labels_db)\n",
    "        ch_score = calinski_harabasz_score(X1, labels_db)\n",
    "    else:\n",
    "        sil_score = -1\n",
    "        db_score = float('inf')\n",
    "        ch_score = 0\n",
    "    \n",
    "    silhouette_scores_1_db.append(sil_score)\n",
    "    davies_bouldin_scores_1_db.append(db_score)\n",
    "    calinski_harabasz_scores_1_db.append(ch_score)\n",
    "    \n",
    "    print(f'eps={eps:.2f}: Clusters={n_clusters}, Noise={noise_percent:.2f}%, Silhouette={sil_score:.4f}')\n",
    "\n",
    "# Выбор лучшего eps по silhouette\n",
    "best_eps_1_db = eps_range[np.argmax(silhouette_scores_1_db)]\n",
    "print(f'\\nЛучшее eps для DBSCAN: {best_eps_1_db:.2f}')\n",
    "print(f'Лучший silhouette score: {max(silhouette_scores_1_db):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Визуализация датасета 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA для визуализации\n",
    "pca = PCA(n_components=2)\n",
    "X1_pca = pca.fit_transform(X1)\n",
    "\n",
    "# Лучший KMeans результат\n",
    "best_kmeans_1 = kmeans_models_1[best_k_1_km][0]\n",
    "labels_best_1_km = kmeans_models_1[best_k_1_km][1]\n",
    "\n",
    "# PCA scatter plot для KMeans\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "scatter = ax.scatter(X1_pca[:, 0], X1_pca[:, 1], c=labels_best_1_km, cmap='viridis', s=50, alpha=0.6)\n",
    "ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%})')\n",
    "ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%})')\n",
    "ax.set_title(f'Датасет 1: KMeans (k={best_k_1_km})')\n",
    "plt.colorbar(scatter, ax=ax, label='Cluster')\n",
    "plt.tight_layout()\n",
    "plt.savefig('artifacts/figures/pca_dataset1_kmeans.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('PCA plot KMeans сохранен')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Метрики vs K для KMeans\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axes[0].plot(list(k_range), silhouette_scores_1_km, marker='o')\n",
    "axes[0].set_xlabel('Number of clusters (k)')\n",
    "axes[0].set_ylabel('Silhouette Score')\n",
    "axes[0].set_title('KMeans: Silhouette vs k')\n",
    "axes[0].grid(True)\n",
    "\n",
    "axes[1].plot(list(k_range), davies_bouldin_scores_1_km, marker='o', color='orange')\n",
    "axes[1].set_xlabel('Number of clusters (k)')\n",
    "axes[1].set_ylabel('Davies-Bouldin Index')\n",
    "axes[1].set_title('KMeans: Davies-Bouldin vs k')\n",
    "axes[1].grid(True)\n",
    "\n",
    "axes[2].plot(list(k_range), calinski_harabasz_scores_1_km, marker='o', color='green')\n",
    "axes[2].set_xlabel('Number of clusters (k)')\n",
    "axes[2].set_ylabel('Calinski-Harabasz Score')\n",
    "axes[2].set_title('KMeans: Calinski-Harabasz vs k')\n",
    "axes[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('artifacts/figures/metrics_dataset1_kmeans.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Метрики KMeans сохранены')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Датасет 2: Анализ и кластеризация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка и EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка датасета 2\n",
    "df2 = pd.read_csv('data/S07-hw-dataset-02.csv')\n",
    "\n",
    "print('=== Датасет 2: Информация ===' )\n",
    "print(f'Размер: {df2.shape}')\n",
    "print(f'\\nПервые строки:')\n",
    "print(df2.head())\n",
    "print(f'\\nТип данных:')\n",
    "print(df2.info())\n",
    "print(f'\\nСтатистика:')\n",
    "print(df2.describe())\n",
    "print(f'\\nПропущенные значения:')\n",
    "print(df2.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка датасета 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отделяем sample_id от признаков\n",
    "sample_ids_2 = df2['sample_id'].copy()\n",
    "X2_raw = df2.drop('sample_id', axis=1)\n",
    "\n",
    "# Обработка пропущенных значений\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X2_imputed = imputer.fit_transform(X2_raw)\n",
    "\n",
    "# Стандартизация признаков\n",
    "scaler = StandardScaler()\n",
    "X2 = scaler.fit_transform(X2_imputed)\n",
    "\n",
    "print('Датасет 2 предобработан')\n",
    "print(f'Форма после предобработки: {X2.shape}')\n",
    "print(f'Среднее: {X2.mean(axis=0)}')\n",
    "print(f'Стандартное отклонение: {X2.std(axis=0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans кластеризация для датасета 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестирование KMeans с разными k\n",
    "k_range = range(2, 21)\n",
    "silhouette_scores_2_km = []\n",
    "davies_bouldin_scores_2_km = []\n",
    "calinski_harabasz_scores_2_km = []\n",
    "kmeans_models_2 = {}\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels_km = kmeans.fit_predict(X2)\n",
    "    kmeans_models_2[k] = (kmeans, labels_km)\n",
    "    \n",
    "    sil_score = silhouette_score(X2, labels_km)\n",
    "    db_score = davies_bouldin_score(X2, labels_km)\n",
    "    ch_score = calinski_harabasz_score(X2, labels_km)\n",
    "    \n",
    "    silhouette_scores_2_km.append(sil_score)\n",
    "    davies_bouldin_scores_2_km.append(db_score)\n",
    "    calinski_harabasz_scores_2_km.append(ch_score)\n",
    "    \n",
    "    print(f'k={k}: Silhouette={sil_score:.4f}, Davies-Bouldin={db_score:.4f}, Calinski-Harabasz={ch_score:.4f}')\n",
    "\n",
    "best_k_2_km = list(k_range)[np.argmax(silhouette_scores_2_km)]\n",
    "print(f'\\nЛучшее k для KMeans: {best_k_2_km}')\n",
    "print(f'Лучший silhouette score: {max(silhouette_scores_2_km):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AgglomerativeClustering для датасета 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестирование AgglomerativeClustering с разными k и linkage\n",
    "k_range_agg = range(2, 21)\n",
    "linkage_types = ['ward', 'complete']\n",
    "\n",
    "silhouette_scores_2_agg = {}\n",
    "davies_bouldin_scores_2_agg = {}\n",
    "calinski_harabasz_scores_2_agg = {}\n",
    "agg_models_2 = {}\n",
    "\n",
    "for linkage in linkage_types:\n",
    "    silhouette_scores_2_agg[linkage] = []\n",
    "    davies_bouldin_scores_2_agg[linkage] = []\n",
    "    calinski_harabasz_scores_2_agg[linkage] = []\n",
    "    agg_models_2[linkage] = {}\n",
    "    \n",
    "    for k in k_range_agg:\n",
    "        agg = AgglomerativeClustering(n_clusters=k, linkage=linkage)\n",
    "        labels_agg = agg.fit_predict(X2)\n",
    "        agg_models_2[linkage][k] = (agg, labels_agg)\n",
    "        \n",
    "        sil_score = silhouette_score(X2, labels_agg)\n",
    "        db_score = davies_bouldin_score(X2, labels_agg)\n",
    "        ch_score = calinski_harabasz_score(X2, labels_agg)\n",
    "        \n",
    "        silhouette_scores_2_agg[linkage].append(sil_score)\n",
    "        davies_bouldin_scores_2_agg[linkage].append(db_score)\n",
    "        calinski_harabasz_scores_2_agg[linkage].append(ch_score)\n",
    "        \n",
    "    print(f'Linkage {linkage}: лучший k = {np.argmax(silhouette_scores_2_agg[linkage]) + 2}, score = {max(silhouette_scores_2_agg[linkage]):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Визуализация датасета 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA для визуализации\n",
    "pca = PCA(n_components=2)\n",
    "X2_pca = pca.fit_transform(X2)\n",
    "\n",
    "# Лучший KMeans результат\n",
    "labels_best_2_km = kmeans_models_2[best_k_2_km][1]\n",
    "\n",
    "# PCA scatter plot для KMeans\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "scatter = ax.scatter(X2_pca[:, 0], X2_pca[:, 1], c=labels_best_2_km, cmap='viridis', s=50, alpha=0.6)\n",
    "ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%})')\n",
    "ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%})')\n",
    "ax.set_title(f'Датасет 2: KMeans (k={best_k_2_km})')\n",
    "plt.colorbar(scatter, ax=ax, label='Cluster')\n",
    "plt.tight_layout()\n",
    "plt.savefig('artifacts/figures/pca_dataset2_kmeans.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('PCA plot KMeans сохранен')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Метрики vs K для Agglomerative\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "for i, linkage in enumerate(linkage_types):\n",
    "    axes[i].plot(list(k_range_agg), silhouette_scores_2_agg[linkage], marker='o', label=f'{linkage}')\n",
    "    axes[i].set_xlabel('Number of clusters (k)')\n",
    "    axes[i].set_ylabel('Silhouette Score')\n",
    "    axes[i].set_title(f'Agglomerative ({linkage}): Silhouette vs k')\n",
    "    axes[i].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('artifacts/figures/metrics_dataset2_agg.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Метрики Agglomerative сохранены')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Датасет 3: Анализ и кластеризация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка и EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка датасета 3\n",
    "df3 = pd.read_csv('data/S07-hw-dataset-03.csv')\n",
    "\n",
    "print('=== Датасет 3: Информация ===' )\n",
    "print(f'Размер: {df3.shape}')\n",
    "print(f'\\nПервые строки:')\n",
    "print(df3.head())\n",
    "print(f'\\nТип данных:')\n",
    "print(df3.info())\n",
    "print(f'\\nСтатистика:')\n",
    "print(df3.describe())\n",
    "print(f'\\nПропущенные значения:')\n",
    "print(df3.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка датасета 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отделяем sample_id от признаков\n",
    "sample_ids_3 = df3['sample_id'].copy()\n",
    "X3_raw = df3.drop('sample_id', axis=1)\n",
    "\n",
    "# Обработка пропущенных значений\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X3_imputed = imputer.fit_transform(X3_raw)\n",
    "\n",
    "# Стандартизация признаков\n",
    "scaler = StandardScaler()\n",
    "X3 = scaler.fit_transform(X3_imputed)\n",
    "\n",
    "print('Датасет 3 предобработан')\n",
    "print(f'Форма после предобработки: {X3.shape}')\n",
    "print(f'Среднее: {X3.mean(axis=0)}')\n",
    "print(f'Стандартное отклонение: {X3.std(axis=0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans кластеризация для датасета 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестирование KMeans с разными k\n",
    "k_range = range(2, 21)\n",
    "silhouette_scores_3_km = []\n",
    "davies_bouldin_scores_3_km = []\n",
    "calinski_harabasz_scores_3_km = []\n",
    "kmeans_models_3 = {}\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels_km = kmeans.fit_predict(X3)\n",
    "    kmeans_models_3[k] = (kmeans, labels_km)\n",
    "    \n",
    "    sil_score = silhouette_score(X3, labels_km)\n",
    "    db_score = davies_bouldin_score(X3, labels_km)\n",
    "    ch_score = calinski_harabasz_score(X3, labels_km)\n",
    "    \n",
    "    silhouette_scores_3_km.append(sil_score)\n",
    "    davies_bouldin_scores_3_km.append(db_score)\n",
    "    calinski_harabasz_scores_3_km.append(ch_score)\n",
    "    \n",
    "    print(f'k={k}: Silhouette={sil_score:.4f}, Davies-Bouldin={db_score:.4f}, Calinski-Harabasz={ch_score:.4f}')\n",
    "\n",
    "best_k_3_km = list(k_range)[np.argmax(silhouette_scores_3_km)]\n",
    "print(f'\\nЛучшее k для KMeans: {best_k_3_km}')\n",
    "print(f'Лучший silhouette score: {max(silhouette_scores_3_km):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN кластеризация для датасета 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестирование DBSCAN с разными eps\n",
    "eps_range = np.linspace(0.2, 1.5, 15)\n",
    "min_samples = 4\n",
    "\n",
    "silhouette_scores_3_db = []\n",
    "davies_bouldin_scores_3_db = []\n",
    "calinski_harabasz_scores_3_db = []\n",
    "noise_percentages_3_db = []\n",
    "dbscan_models_3 = {}\n",
    "\n",
    "for eps in eps_range:\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "    labels_db = dbscan.fit_predict(X3)\n",
    "    dbscan_models_3[eps] = (dbscan, labels_db)\n",
    "    \n",
    "    n_clusters = len(set(labels_db)) - (1 if -1 in labels_db else 0)\n",
    "    noise_points = np.sum(labels_db == -1)\n",
    "    noise_percent = (noise_points / len(labels_db)) * 100\n",
    "    noise_percentages_3_db.append(noise_percent)\n",
    "    \n",
    "    if n_clusters > 1 and len(set(labels_db)) > 1:\n",
    "        sil_score = silhouette_score(X3, labels_db)\n",
    "        db_score = davies_bouldin_score(X3, labels_db)\n",
    "        ch_score = calinski_harabasz_score(X3, labels_db)\n",
    "    else:\n",
    "        sil_score = -1\n",
    "        db_score = float('inf')\n",
    "        ch_score = 0\n",
    "    \n",
    "    silhouette_scores_3_db.append(sil_score)\n",
    "    davies_bouldin_scores_3_db.append(db_score)\n",
    "    calinski_harabasz_scores_3_db.append(ch_score)\n",
    "    \n",
    "    print(f'eps={eps:.2f}: Clusters={n_clusters}, Noise={noise_percent:.2f}%, Silhouette={sil_score:.4f}')\n",
    "\n",
    "best_eps_3_db = eps_range[np.argmax(silhouette_scores_3_db)]\n",
    "print(f'\\nЛучшее eps для DBSCAN: {best_eps_3_db:.2f}')\n",
    "print(f'Лучший silhouette score: {max(silhouette_scores_3_db):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Визуализация датасета 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA для визуализации\n",
    "pca = PCA(n_components=2)\n",
    "X3_pca = pca.fit_transform(X3)\n",
    "\n",
    "# Лучший KMeans результат\n",
    "labels_best_3_km = kmeans_models_3[best_k_3_km][1]\n",
    "\n",
    "# PCA scatter plot для KMeans\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "scatter = ax.scatter(X3_pca[:, 0], X3_pca[:, 1], c=labels_best_3_km, cmap='viridis', s=50, alpha=0.6)\n",
    "ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%})')\n",
    "ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%})')\n",
    "ax.set_title(f'Датасет 3: KMeans (k={best_k_3_km})')\n",
    "plt.colorbar(scatter, ax=ax, label='Cluster')\n",
    "plt.tight_layout()\n",
    "plt.savefig('artifacts/figures/pca_dataset3_kmeans.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('PCA plot KMeans сохранен')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Метрики vs eps для DBSCAN\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(eps_range, silhouette_scores_3_db, marker='o', color='purple')\n",
    "ax.set_xlabel('eps parameter')\n",
    "ax.set_ylabel('Silhouette Score')\n",
    "ax.set_title('DBSCAN: Silhouette vs eps')\n",
    "ax.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('artifacts/figures/metrics_dataset3_dbscan.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Метрики DBSCAN сохранены')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка стабильности (Stability Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка стабильности KMeans для датасета 1\n",
    "# Запускаем KMeans 5 раз с разными random_state\n",
    "random_states = [42, 123, 456, 789, 999]\n",
    "stability_labels = []\n",
    "\n",
    "print('=== Проверка стабильности KMeans (Датасет 1) ===' )\n",
    "for rs in random_states:\n",
    "    kmeans = KMeans(n_clusters=best_k_1_km, random_state=rs, n_init=10)\n",
    "    labels = kmeans.fit_predict(X1)\n",
    "    stability_labels.append(labels)\n",
    "    print(f'Random state {rs}: KMeans выполнен')\n",
    "\n",
    "# Сравнение результатов\n",
    "ari_scores = []\n",
    "print(f'\\nARI scores между разными запусками:')\n",
    "for i in range(len(stability_labels) - 1):\n",
    "    ari = adjusted_rand_score(stability_labels[i], stability_labels[i+1])\n",
    "    ari_scores.append(ari)\n",
    "    print(f'Run {i+1} vs Run {i+2}: ARI = {ari:.4f}')\n",
    "\n",
    "print(f'\\nСредний ARI score: {np.mean(ari_scores):.4f}')\n",
    "print(f'Минимальный ARI score: {np.min(ari_scores):.4f}')\n",
    "print(f'Максимальный ARI score: {np.max(ari_scores):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохранение меток кластеров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение меток для датасета 1\n",
    "labels_df1 = pd.DataFrame({\n",
    "    'sample_id': sample_ids_1,\n",
    "    'cluster_label': labels_best_1_km\n",
    "})\n",
    "labels_df1.to_csv('artifacts/labels/labels_hw07_ds1.csv', index=False)\n",
    "print('Датасет 1 метки сохранены')\n",
    "\n",
    "# Сохранение меток для датасета 2\n",
    "labels_df2 = pd.DataFrame({\n",
    "    'sample_id': sample_ids_2,\n",
    "    'cluster_label': labels_best_2_km\n",
    "})\n",
    "labels_df2.to_csv('artifacts/labels/labels_hw07_ds2.csv', index=False)\n",
    "print('Датасет 2 метки сохранены')\n",
    "\n",
    "# Сохранение меток для датасета 3\n",
    "labels_df3 = pd.DataFrame({\n",
    "    'sample_id': sample_ids_3,\n",
    "    'cluster_label': labels_best_3_km\n",
    "})\n",
    "labels_df3.to_csv('artifacts/labels/labels_hw07_ds3.csv', index=False)\n",
    "print('Датасет 3 метки сохранены')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохранение метрик в JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание объекта со всеми метриками\n",
    "metrics_summary = {\n",
    "    'dataset_1': {\n",
    "        'KMeans': {\n",
    "            'best_k': int(best_k_1_km),\n",
    "            'metrics': {\n",
    "                'silhouette_score': float(max(silhouette_scores_1_km)),\n",
    "                'davies_bouldin_score': float(min(davies_bouldin_scores_1_km)),\n",
    "                'calinski_harabasz_score': float(max(calinski_harabasz_scores_1_km))\n",
    "            }\n",
    "        },\n",
    "        'DBSCAN': {\n",
    "            'best_eps': float(best_eps_1_db),\n",
    "            'min_samples': 5,\n",
    "            'metrics': {\n",
    "                'silhouette_score': float(max(silhouette_scores_1_db)),\n",
    "                'davies_bouldin_score': float(min([x for x in davies_bouldin_scores_1_db if x != float('inf')])),\n",
    "                'noise_percentage': float(max([noise_percentages_1_db[i] for i in range(len(noise_percentages_1_db)) if silhouette_scores_1_db[i] == max(silhouette_scores_1_db)]))\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'dataset_2': {\n",
    "        'KMeans': {\n",
    "            'best_k': int(best_k_2_km),\n",
    "            'metrics': {\n",
    "                'silhouette_score': float(max(silhouette_scores_2_km)),\n",
    "                'davies_bouldin_score': float(min(davies_bouldin_scores_2_km)),\n",
    "                'calinski_harabasz_score': float(max(calinski_harabasz_scores_2_km))\n",
    "            }\n",
    "        },\n",
    "        'AgglomerativeClustering': {\n",
    "            'best_linkage': 'ward' if max(silhouette_scores_2_agg['ward']) > max(silhouette_scores_2_agg['complete']) else 'complete',\n",
    "            'best_k': int(np.argmax(silhouette_scores_2_agg['ward' if max(silhouette_scores_2_agg['ward']) > max(silhouette_scores_2_agg['complete']) else 'complete']) + 2),\n",
    "            'metrics': {\n",
    "                'silhouette_score': float(max(max(silhouette_scores_2_agg['ward']), max(silhouette_scores_2_agg['complete']))),\n",
    "                'davies_bouldin_score': float(min(min(davies_bouldin_scores_2_agg['ward']), min(davies_bouldin_scores_2_agg['complete']))),\n",
    "                'calinski_harabasz_score': float(max(max(calinski_harabasz_scores_2_agg['ward']), max(calinski_harabasz_scores_2_agg['complete'])))\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'dataset_3': {\n",
    "        'KMeans': {\n",
    "            'best_k': int(best_k_3_km),\n",
    "            'metrics': {\n",
    "                'silhouette_score': float(max(silhouette_scores_3_km)),\n",
    "                'davies_bouldin_score': float(min(davies_bouldin_scores_3_km)),\n",
    "                'calinski_harabasz_score': float(max(calinski_harabasz_scores_3_km))\n",
    "            }\n",
    "        },\n",
    "        'DBSCAN': {\n",
    "            'best_eps': float(best_eps_3_db),\n",
    "            'min_samples': 4,\n",
    "            'metrics': {\n",
    "                'silhouette_score': float(max(silhouette_scores_3_db)),\n",
    "                'davies_bouldin_score': float(min([x for x in davies_bouldin_scores_3_db if x != float('inf')])),\n",
    "                'noise_percentage': float(max([noise_percentages_3_db[i] for i in range(len(noise_percentages_3_db)) if silhouette_scores_3_db[i] == max(silhouette_scores_3_db)]))\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Сохранение в JSON файл\n",
    "with open('artifacts/metrics_summary.json', 'w') as f:\n",
    "    json.dump(metrics_summary, f, indent=2)\n",
    "\n",
    "print('Метрики сохранены в JSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание объекта с лучшими конфигурациями\n",
    "best_configs = {\n",
    "    'dataset_1': {\n",
    "        'algorithm': 'KMeans',\n",
    "        'parameters': {\n",
    "            'n_clusters': int(best_k_1_km),\n",
    "            'random_state': 42,\n",
    "            'n_init': 10\n",
    "        },\n",
    "        'performance': {\n",
    "            'silhouette_score': float(max(silhouette_scores_1_km))\n",
    "        }\n",
    "    },\n",
    "    'dataset_2': {\n",
    "        'algorithm': 'AgglomerativeClustering',\n",
    "        'parameters': {\n",
    "            'n_clusters': int(np.argmax(silhouette_scores_2_agg['ward']) + 2),\n",
    "            'linkage': 'ward'\n",
    "        },\n",
    "        'performance': {\n",
    "            'silhouette_score': float(max(silhouette_scores_2_agg['ward']))\n",
    "        }\n",
    "    },\n",
    "    'dataset_3': {\n",
    "        'algorithm': 'DBSCAN',\n",
    "        'parameters': {\n",
    "            'eps': float(best_eps_3_db),\n",
    "            'min_samples': 4\n",
    "        },\n",
    "        'performance': {\n",
    "            'silhouette_score': float(max(silhouette_scores_3_db))\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Сохранение в JSON файл\n",
    "with open('artifacts/best_configs.json', 'w') as f:\n",
    "    json.dump(best_configs, f, indent=2)\n",
    "\n",
    "print('Конфигурации сохранены в JSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Итоговый отчет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== ИТОГОВЫЙ ОТЧЕТ HW07 ===')\n",
    "print()\n",
    "print('ДАТАСЕТ 1: Числовые признаки с разными масштабами')\n",
    "print(f'  Выбранный метод: KMeans (k={best_k_1_km})')\n",
    "print(f'  Лучший silhouette score: {max(silhouette_scores_1_km):.4f}')\n",
    "print(f'  Вызовы: различные масштабы признаков, необходима стандартизация')\n",
    "print()\n",
    "print('ДАТАСЕТ 2: Нелинейная структура с выбросами')\n",
    "best_link = 'ward' if max(silhouette_scores_2_agg['ward']) > max(silhouette_scores_2_agg['complete']) else 'complete'\n",
    "print(f'  Выбранный метод: AgglomerativeClustering ({best_link} linkage)')\n",
    "print(f'  Лучший k: {np.argmax(silhouette_scores_2_agg[best_link]) + 2}')\n",
    "print(f'  Лучший silhouette score: {max(silhouette_scores_2_agg[best_link]):.4f}')\n",
    "print(f'  Вызовы: иерархическая кластеризация лучше справляется с нелинейностью')\n",
    "print()\n",
    "print('ДАТАСЕТ 3: Кластеры с разной плотностью')\n",
    "print(f'  Выбранный метод: DBSCAN (eps={best_eps_3_db:.2f})')\n",
    "print(f'  Лучший silhouette score: {max(silhouette_scores_3_db):.4f}')\n",
    "print(f'  Вызовы: DBSCAN способен обнаруживать кластеры произвольной формы')\n",
    "print()\n",
    "print('ПРОВЕРКА СТАБИЛЬНОСТИ:')\n",
    "print(f'  Датасет 1 (KMeans): средний ARI = {np.mean(ari_scores):.4f}')\n",
    "print(f'  KMeans показывает хорошую стабильность')\n",
    "print()\n",
    "print('=== ФАЙЛЫ СОХРАНЕНЫ ===')\n",
    "print('  - artifacts/figures/: 6 PNG изображений')\n",
    "print('  - artifacts/labels/: 3 CSV файла с метками')\n",
    "print('  - artifacts/metrics_summary.json')\n",
    "print('  - artifacts/best_configs.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}