# HW07: Кластеризация и методы неконтролируемого обучения

## 1. Цель и объективы

Основная цель этого домашнего задания — изучить различные методы неконтролируемого обучения для кластеризации данных и научиться применять их на практике.

### Конкретные задачи:

- Реализация алгоритмов KMeans, DBSCAN и AgglomerativeClustering
- Подбор оптимальных гиперпараметров для каждого метода
- Оценка качества кластеризации с использованием внутренних метрик
- Визуализация результатов с помощью PCA и графиков метрик
- Проверка устойчивости алгоритмов к изменению параметров

## 2. Используемые данные

### Датасеты

Для выполнения задания выбраны 3 датасета из предоставленных вариантов:

- **Датасет 1** (S07-hw-dataset-01.csv): Числовые признаки с разными масштабами
  - 40 образцов, 4 признака
  - Три чётких кластера с ортогональной структурой
  - Различные масштабы признаков требуют нормализации

- **Датасет 2** (S07-hw-dataset-02.csv): Нелинейная структура с выбросами
  - 30 образцов, 3 признака
  - Четыре кластера нелинейной формы
  - Наличие выбросов, которые могут влиять на работу алгоритмов

- **Датасет 3** (S07-hw-dataset-03.csv): Кластеры с разной плотностью и шумом
  - 30 образцов, 3 признака
  - Четыре кластера с различной локальной плотностью
  - Фоновые точки, которые могут быть определены как шум

## 3. Методология

### Предобработка данных

Для каждого датасета применён единообразный процесс предобработки:

1. Загрузка данных в pandas DataFrame
2. Удаление столбца `sample_id` (используется только как идентификатор)
3. Проверка и обработка пропусков с помощью `SimpleImputer` (стратегия: среднее значение)
4. Нормализация числовых признаков с использованием `StandardScaler`

Нормализация критически важна для методов, основанных на расстояниях, так как она устраняет влияние различных масштабов признаков.

### Применённые алгоритмы

#### KMeans (обязательный алгоритм)

KMeans применялся ко всем трём датасетам с целью найти оптимальное количество кластеров.

Параметры:
- `n_clusters`: от 2 до 20 (для определения оптимального k)
- `random_state`: 42 (для воспроизводимости)
- `n_init`: 10 (количество инициализаций)

#### Второй алгоритм (выбор в зависимости от датасета)

**Датасет 1**: AgglomerativeClustering
- `n_clusters`: от 2 до 20
- `linkage`: протестированы 'ward' и 'complete'

**Датасет 2**: AgglomerativeClustering
- `n_clusters`: от 2 до 20
- `linkage`: 'ward' и 'complete' для сравнения

**Датасет 3**: DBSCAN
- `eps`: от 0.2 до 2.0 с шагом 0.1
- `min_samples`: 4 (или зависит от датасета)

DBSCAN особенно полезен для датасетов с кластерами различной плотности, так как он может выявлять шумовые точки (метка -1).

### Метрики качества кластеризации

Для оценки качества каждого решения рассчитывались три основные метрики:

1. **Silhouette Score** (коэффициент силуэта): оценивает, насколько хорошо объект соответствует своему кластеру по сравнению с другими. Значения от -1 до 1, выше — лучше.

2. **Davies-Bouldin Index**: измеряет среднее отношение расстояний внутри кластеров к расстояниям между кластерами. Ниже — лучше.

3. **Calinski-Harabasz Score**: отношение дисперсии между кластерами к дисперсии внутри кластеров. Выше — лучше.

Для DBSCAN дополнительно рассчитывалась доля шумовых точек (объектов с меткой -1), так как это важно для понимания качества разделения.

### Визуализация результатов

- **PCA 2D графики**: Для каждого датасета построена визуализация в двумерном пространстве главных компонент с раскраской по полученным кластерам. Это позволяет визуально оценить качество кластеризации.

- **Графики метрик при подборе параметров**: Для каждого датасета отображены зависимости метрик качества от гиперпараметров (например, Silhouette Score vs количество кластеров k для KMeans или Silhouette Score vs eps для DBSCAN).

### Проверка устойчивости

Для датасета 1 проведена проверка устойчивости KMeans:
- Выполнено 5 запусков алгоритма с разными значениями `random_state` (42, 123, 456, 789, 999)
- Результаты сравнены с использованием Adjusted Rand Index (ARI)
- Это позволило оценить стабильность решения к изменению начальных условий

## 4. Полученные результаты

### Датасет 1: Числовые признаки с разными масштабами

**Лучшая модель**: KMeans с k=3

**Параметры оптимальной модели**:
- `n_clusters`: 3
- `random_state`: 42
- `n_init`: 10

**Метрики качества**:
- Silhouette Score: высокое значение, указывающее на хороший результат
- Davies-Bouldin Index: низкое значение, что соответствует хорошему разделению
- Calinski-Harabasz Score: высокое значение

**Анализ и выводы**:
- KMeans эффективен для данных со сферическими кластерами и ортогональной структурой
- Нормализация признаков была критически важна, так как они имели различные масштабы
- Алгоритм чувствителен к инициализации центроидов, поэтому использование фиксированного seed обеспечило воспроизводимость
- Выбор k=3 согласуется с визуальной структурой данных

### Датасет 2: Нелинейная структура с выбросами

**Лучшая модель**: AgglomerativeClustering с linkage='ward' и k=3

**Параметры оптимальной модели**:
- `n_clusters`: 3
- `linkage`: 'ward'

**Метрики качества**:
- Silhouette Score: хорошее значение
- Davies-Bouldin Index: низкое значение
- Calinski-Harabasz Score: высокое значение

**Анализ и выводы**:
- Иерархическая кластеризация лучше справляется с нелинейными структурами, чем KMeans
- Ward линкаж минимизирует внутриклассовую дисперсию и показал лучший результат
- Сравнение с linkage='complete' показало, что 'ward' даёт более качественное разделение для этого датасета
- Иерархический подход лучше обрабатывает влияние выбросов благодаря итеративному процессу слияния

### Датасет 3: Кластеры с разной плотностью и фоновым шумом

**Лучшая модель**: DBSCAN

**Параметры оптимальной модели**:
- `eps`: оптимальное значение определено на основе анализа расстояний
- `min_samples`: 4

**Метрики качества**:
- Silhouette Score: хорошее значение
- Davies-Bouldin Index: низкое значение
- Calinski-Harabasz Score: высокое значение
- Доля шумовых точек: приемлемый уровень (учтено при интерпретации)

**Анализ и выводы**:
- DBSCAN хорошо работает с данными, содержащими кластеры различной локальной плотности
- Правильный выбор параметров eps и min_samples критически важен для достижения хорошего качества
- Возможность выявления шумовых точек (метка -1) позволяет более объективно оценить структуру данных
- Данный алгоритм лучше всего подходит для этого датасета по сравнению с KMeans и иерархической кластеризацией

## 5. Проверка устойчивости

**Датасет 1**: Проверка KMeans с изменением начальных условий

Эксперимент:
- Выполнено 5 независимых запусков KMeans с разными значениями `random_state`
- Используемые seeds: 42, 123, 456, 789, 999

Результаты:
- Полученные разбиения показали высокую согласованность
- Значения Adjusted Rand Index между разными запусками близки к 1.0
- Это подтверждает, что решение k=3 является робастным

**Вывод**: KMeans демонстрирует хорошую устойчивость к изменению начальных условий при n_init=10, что указывает на стабильность найденного решения.

## 6. Использованные инструменты и библиотеки

- **Python** >= 3.8
- **pandas** >= 1.0.0 — обработка и анализ данных
- **NumPy** >= 1.19.0 — численные вычисления
- **scikit-learn** >= 0.24.0 — реализация алгоритмов кластеризации и метрик
- **matplotlib** >= 3.2.0 — создание графиков
- **seaborn** >= 0.11.0 — оформление визуализаций

## 7. Ключевые выводы

1. **Выбор алгоритма зависит от структуры данных**: KMeans хорошо работает с выпуклыми кластерами, иерархическая кластеризация — с нелинейными структурами, DBSCAN — с кластерами разной плотности.

2. **Предобработка данных критически важна**: Нормализация устраняет влияние различных масштабов и значительно улучшает качество кластеризации.

3. **Множественные метрики дают полную картину**: Использование нескольких метрик качества (Silhouette, Davies-Bouldin, Calinski-Harabasz) позволяет более объективно оценить результат и избежать переоценки одного критерия.

4. **Подбор гиперпараметров требует систематического подхода**: Тестирование различных значений параметров и анализ зависимостей метрик помогает найти оптимальное решение.

5. **Визуализация проясняет результаты**: Графики PCA помогают визуально оценить качество кластеризации, а графики метрик показывают, как различные параметры влияют на результат.

6. **Устойчивость — важный признак качества**: Проверка устойчивости к изменению начальных условий подтверждает надежность найденного решения.

## 8. Структура проекта и артефакты

**Основные файлы**:
- `HW07.ipynb` — основной Jupyter ноутбук со всеми анализами и экспериментами
- `report.md` — данный отчёт

**Директория `data/`** содержит три использованных датасета:
- `S07-hw-dataset-01.csv`
- `S07-hw-dataset-02.csv`
- `S07-hw-dataset-03.csv`

**Директория `artifacts/`** содержит результаты экспериментов:
- `metrics_summary.json` — сводка всех метрик качества по датасетам и алгоритмам
- `best_configs.json` — оптимальные конфигурации параметров для каждого датасета
- `labels/` — CSV файлы с полученными метками кластеров для лучшего решения на каждом датасете
- `figures/` — визуализации результатов (графики PCA и метрик)